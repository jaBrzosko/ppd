{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10200063,"sourceType":"datasetVersion","datasetId":6302968}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.metrics import accuracy_score\nimport string","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T17:13:44.667822Z","iopub.execute_input":"2024-12-16T17:13:44.668567Z","iopub.status.idle":"2024-12-16T17:13:46.795740Z","shell.execute_reply.started":"2024-12-16T17:13:44.668508Z","shell.execute_reply":"2024-12-16T17:13:46.794780Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"def replace_polish_lowercase(text):\n    polish_to_latin = {\n        'Ä…': 'a', 'Ä‡': 'c', 'Ä™': 'e', 'Å‚': 'l', 'Å„': 'n', \n        'Ã³': 'o', 'Å›': 's', 'Åº': 'z', 'Å¼': 'z'\n    }\n    return ''.join(polish_to_latin.get(char, char) for char in text)\n\ndef preprocess_text(text):\n    # Lowercase\n    text = text.lower()\n    # Remove punctuation\n    text = text.translate(str.maketrans('', '', string.punctuation))\n    # Remove polish letters\n    text = replace_polish_lowercase(text)\n    # Tokenize (split by whitespace)\n    tokens = text.split()\n    return ' '.join(tokens)  # Join tokens back into a string for TF-IDF","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T17:13:46.797354Z","iopub.execute_input":"2024-12-16T17:13:46.797920Z","iopub.status.idle":"2024-12-16T17:13:46.804409Z","shell.execute_reply.started":"2024-12-16T17:13:46.797867Z","shell.execute_reply":"2024-12-16T17:13:46.803515Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"FILENAME_DEV = '/kaggle/input/dataset-conll/all.sentence.dev.txt'\nFILENAME_TRAIN = '/kaggle/input/dataset-conll/all.sentence.train.txt'\nFILENAME_TEST = '/kaggle/input/dataset-conll/all.sentence.test.txt'\n\nLABELS = {\n    \"__label__z_minus_m\": \"Negative sentiment\", \n    \"__label__z_plus_m\": \"Positive sentiment\",\n    \"__label__z_zero\": \"No sentiment\",\n    \"__label__z_amb\": \"Unsure\",\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T17:13:46.805506Z","iopub.execute_input":"2024-12-16T17:13:46.805813Z","iopub.status.idle":"2024-12-16T17:13:46.817601Z","shell.execute_reply.started":"2024-12-16T17:13:46.805789Z","shell.execute_reply":"2024-12-16T17:13:46.816688Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def load_df(filename):\n    with open(filename, 'r', encoding=\"utf8\") as f:\n        lines = f.readlines()\n        data = [line.strip() for line in lines]\n        # get last word from each item as a label and match with data\n        labeled_data = []\n        for item in data:\n            label = item.split()[-1]\n            sentence_data = ' '.join(item.split()[:-1])\n            labeled_data.append((sentence_data, LABELS[label]))\n\n        # create a dataframe\n        df = pd.DataFrame(labeled_data, columns=['text', 'labels'])\n        return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T17:13:46.819310Z","iopub.execute_input":"2024-12-16T17:13:46.819559Z","iopub.status.idle":"2024-12-16T17:13:46.828881Z","shell.execute_reply.started":"2024-12-16T17:13:46.819530Z","shell.execute_reply":"2024-12-16T17:13:46.828038Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Read data","metadata":{}},{"cell_type":"code","source":"df_train = load_df(FILENAME_TRAIN)\ndf_test = load_df(FILENAME_TEST)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T17:13:46.829548Z","iopub.execute_input":"2024-12-16T17:13:46.829829Z","iopub.status.idle":"2024-12-16T17:13:47.293797Z","shell.execute_reply.started":"2024-12-16T17:13:46.829800Z","shell.execute_reply":"2024-12-16T17:13:47.293027Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"df_train['text'] = df_train['text'].apply(preprocess_text)\ndf_test['text'] = df_test['text'].apply(preprocess_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T17:13:47.294891Z","iopub.execute_input":"2024-12-16T17:13:47.295260Z","iopub.status.idle":"2024-12-16T17:13:48.502998Z","shell.execute_reply.started":"2024-12-16T17:13:47.295223Z","shell.execute_reply":"2024-12-16T17:13:48.502329Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"df_train.sample(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T17:13:48.503966Z","iopub.execute_input":"2024-12-16T17:13:48.504233Z","iopub.status.idle":"2024-12-16T17:13:48.522492Z","shell.execute_reply.started":"2024-12-16T17:13:48.504209Z","shell.execute_reply":"2024-12-16T17:13:48.521735Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                                    text              labels\n37274  do trzech razy sztuka ktos nareszcie potrafil ...  Positive sentiment\n44200             nie zawarla z nami zadnego kontraktu 2              Unsure\n2457   polecam zarowno na duze imprezy jak i kameraln...  Positive sentiment\n499    polecam przy okazji pobytu odwiedzic piekne mi...  Positive sentiment\n42417  obecnosc warto chodzic pani doktor dlugosz ma ...              Unsure","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>37274</th>\n      <td>do trzech razy sztuka ktos nareszcie potrafil ...</td>\n      <td>Positive sentiment</td>\n    </tr>\n    <tr>\n      <th>44200</th>\n      <td>nie zawarla z nami zadnego kontraktu 2</td>\n      <td>Unsure</td>\n    </tr>\n    <tr>\n      <th>2457</th>\n      <td>polecam zarowno na duze imprezy jak i kameraln...</td>\n      <td>Positive sentiment</td>\n    </tr>\n    <tr>\n      <th>499</th>\n      <td>polecam przy okazji pobytu odwiedzic piekne mi...</td>\n      <td>Positive sentiment</td>\n    </tr>\n    <tr>\n      <th>42417</th>\n      <td>obecnosc warto chodzic pani doktor dlugosz ma ...</td>\n      <td>Unsure</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"# BERT fine tuning","metadata":{}},{"cell_type":"code","source":"from transformers import (\n    AutoTokenizer, \n    AutoModelForSequenceClassification,\n    TrainingArguments,\n    Trainer\n)\nimport torch\nfrom torch.utils.data import Dataset\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T17:13:48.523334Z","iopub.execute_input":"2024-12-16T17:13:48.523587Z","iopub.status.idle":"2024-12-16T17:14:08.606660Z","shell.execute_reply.started":"2024-12-16T17:13:48.523557Z","shell.execute_reply":"2024-12-16T17:14:08.606027Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"dkleczek/bert-base-polish-uncased-v1\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    \"dkleczek/bert-base-polish-uncased-v1\",\n    num_labels=4\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T17:14:08.607806Z","iopub.execute_input":"2024-12-16T17:14:08.608455Z","iopub.status.idle":"2024-12-16T17:14:13.518309Z","shell.execute_reply.started":"2024-12-16T17:14:08.608416Z","shell.execute_reply":"2024-12-16T17:14:13.517478Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90fe862cf0934cf4872a0933f0b9b098"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/478 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c2852fe55e34442ae29a3cfe44d719a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/495k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a0207a02fe24e72a598e66b20f87017"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad341fcbb1f44c189842db7810b60b73"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/531M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5009906f0c84451ca334dcdd0cfc7525"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dkleczek/bert-base-polish-uncased-v1 and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"class TextClassificationDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_length=128):\n        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=max_length)\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T17:14:13.521424Z","iopub.execute_input":"2024-12-16T17:14:13.522099Z","iopub.status.idle":"2024-12-16T17:14:13.527142Z","shell.execute_reply.started":"2024-12-16T17:14:13.522070Z","shell.execute_reply":"2024-12-16T17:14:13.526194Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def prepare_data_for_training(df):\n    label_map = {\n        'Negative sentiment': 0,\n        'No sentiment': 1,\n        'Unsure': 2,\n        'Positive sentiment': 3\n    }\n    \n    labels = [label_map[label] for label in df['labels']]\n    texts = df['text'].tolist()\n    \n    return texts, labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T17:14:13.528299Z","iopub.execute_input":"2024-12-16T17:14:13.528940Z","iopub.status.idle":"2024-12-16T17:14:13.543374Z","shell.execute_reply.started":"2024-12-16T17:14:13.528902Z","shell.execute_reply":"2024-12-16T17:14:13.542629Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def train_classifier(train_df, test_df):\n    train_texts, train_labels = prepare_data_for_training(train_df)\n    test_texts, test_labels = prepare_data_for_training(test_df)\n    \n    train_dataset = TextClassificationDataset(train_texts, train_labels, tokenizer)\n    test_dataset = TextClassificationDataset(test_texts, test_labels, tokenizer)\n\n    training_args = TrainingArguments(\n        output_dir=\"./results\",\n        num_train_epochs=1,\n        per_device_train_batch_size=16,\n        per_device_eval_batch_size=16,\n        warmup_steps=500,\n        weight_decay=0.01,\n        logging_dir=\"./logs\",\n        logging_steps=10,\n        evaluation_strategy=\"epoch\",\n        save_strategy=\"epoch\",\n        load_best_model_at_end=True,\n        report_to=[\"none\"],\n    )\n\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_dataset,\n        eval_dataset=test_dataset,\n    )\n\n    trainer.train()\n\n    return trainer, model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T17:14:13.544160Z","iopub.execute_input":"2024-12-16T17:14:13.544408Z","iopub.status.idle":"2024-12-16T17:14:13.553659Z","shell.execute_reply.started":"2024-12-16T17:14:13.544385Z","shell.execute_reply":"2024-12-16T17:14:13.552901Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def predict(texts, model):\n    inputs = tokenizer(texts, truncation=True, padding=True, return_tensors=\"pt\").to('cuda')\n    outputs = model(**inputs)\n    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n    \n    label_map_reverse = {\n        0: 'Negative sentiment',\n        1: 'No sentiment',\n        2: 'Unsure',\n        3: 'Positive sentiment'\n    }\n    \n    pred_labels = [label_map_reverse[pred.argmax()] for pred in predictions.detach().numpy()]\n    return pred_labels, predictions.detach().cpu().numpy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T17:14:13.554511Z","iopub.execute_input":"2024-12-16T17:14:13.554758Z","iopub.status.idle":"2024-12-16T17:14:13.568222Z","shell.execute_reply.started":"2024-12-16T17:14:13.554735Z","shell.execute_reply":"2024-12-16T17:14:13.567507Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"trainer, model = train_classifier(df_train, df_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T17:14:13.569159Z","iopub.execute_input":"2024-12-16T17:14:13.569479Z","iopub.status.idle":"2024-12-16T17:26:12.433924Z","shell.execute_reply.started":"2024-12-16T17:14:13.569445Z","shell.execute_reply":"2024-12-16T17:26:12.433236Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/531M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a8c8b88b44c4750826b2d6455708015"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1437' max='1437' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1437/1437 11:51, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.598000</td>\n      <td>0.567414</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"model.save_pretrained(\"/kaggle/working/results\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T17:26:12.434886Z","iopub.execute_input":"2024-12-16T17:26:12.435170Z","iopub.status.idle":"2024-12-16T17:26:13.656862Z","shell.execute_reply.started":"2024-12-16T17:26:12.435144Z","shell.execute_reply":"2024-12-16T17:26:13.655916Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"test_texts, test_labels = prepare_data_for_training(df_test)\ntest_dataset = TextClassificationDataset(test_texts, test_labels, tokenizer)\n\nfrom torch.utils.data import DataLoader\nfrom sklearn.metrics import accuracy_score\nimport torch\n\ntest_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n\nmodel.eval()\n\nall_preds = []\nall_labels = []\n\nwith torch.no_grad():\n    for batch in test_loader:\n        inputs = {key: val.to(model.device) for key, val in batch.items() if key != \"labels\"}\n        labels = batch['labels'].to(model.device)\n\n        # Forward pass\n        outputs = model(**inputs)\n        preds = torch.argmax(outputs.logits, dim=1)\n\n        # Collect predictions and labels\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n\n# Calculate accuracy\naccuracy = accuracy_score(all_labels, all_preds)\nprint(f\"Accuracy: {accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T17:52:18.444218Z","iopub.execute_input":"2024-12-16T17:52:18.444575Z","iopub.status.idle":"2024-12-16T17:52:56.093518Z","shell.execute_reply.started":"2024-12-16T17:52:18.444545Z","shell.execute_reply":"2024-12-16T17:52:56.092511Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.7869\n","output_type":"stream"}],"execution_count":18}]}