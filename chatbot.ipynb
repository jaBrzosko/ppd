{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_polish_lowercase(text):\n",
    "    polish_to_latin = {\n",
    "        'ą': 'a', 'ć': 'c', 'ę': 'e', 'ł': 'l', 'ń': 'n', \n",
    "        'ó': 'o', 'ś': 's', 'ź': 'z', 'ż': 'z'\n",
    "    }\n",
    "    return ''.join(polish_to_latin.get(char, char) for char in text)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Remove polish letters\n",
    "    text = replace_polish_lowercase(text)\n",
    "    # Tokenize (split by whitespace)\n",
    "    tokens = text.split()\n",
    "    return ' '.join(tokens)  # Join tokens back into a string for TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME_DEV = './data/dataset_conll/all.sentence.dev.txt'\n",
    "FILENAME_TRAIN = './data/dataset_conll/all.sentence.train.txt'\n",
    "FILENAME_TEST = './data/dataset_conll/all.sentence.test.txt'\n",
    "\n",
    "LABELS = {\n",
    "    \"__label__z_minus_m\": \"Negative sentiment\", \n",
    "    \"__label__z_plus_m\": \"Positive sentiment\",\n",
    "    \"__label__z_zero\": \"No sentiment\",\n",
    "    \"__label__z_amb\": \"Unsure\",\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df(filename):\n",
    "    with open(filename, 'r', encoding=\"utf8\") as f:\n",
    "        lines = f.readlines()\n",
    "        data = [line.strip() for line in lines]\n",
    "        # get last word from each item as a label and match with data\n",
    "        labeled_data = []\n",
    "        for item in data:\n",
    "            label = item.split()[-1]\n",
    "            sentence_data = ' '.join(item.split()[:-1])\n",
    "            labeled_data.append((sentence_data, LABELS[label]))\n",
    "\n",
    "        # create a dataframe\n",
    "        df = pd.DataFrame(labeled_data, columns=['sentence', 'label'])\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = load_df(FILENAME_TRAIN)\n",
    "df_test = load_df(FILENAME_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Early preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['processed_sentence'] = df_train['sentence'].apply(preprocess_text)\n",
    "df_test['processed_sentence'] = df_test['sentence'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>processed_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17279</th>\n",
       "      <td>Po tygodniu pytanie ponowił em .</td>\n",
       "      <td>No sentiment</td>\n",
       "      <td>po tygodniu pytanie ponowil em</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4164</th>\n",
       "      <td>Niestety nie można też otwierać okien w pokoja...</td>\n",
       "      <td>Negative sentiment</td>\n",
       "      <td>niestety nie mozna tez otwierac okien w pokojach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11742</th>\n",
       "      <td>Inny endokrynolog od razu stwierdził że przy t...</td>\n",
       "      <td>Negative sentiment</td>\n",
       "      <td>inny endokrynolog od razu stwierdzil ze przy t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13645</th>\n",
       "      <td>Leżaki od rana pozajmowane , nie ma gdzie się ...</td>\n",
       "      <td>Negative sentiment</td>\n",
       "      <td>lezaki od rana pozajmowane nie ma gdzie sie po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6680</th>\n",
       "      <td>\" Ich badania pomogły w zrozumieniu wielu proc...</td>\n",
       "      <td>No sentiment</td>\n",
       "      <td>ich badania pomogly w zrozumieniu wielu proces...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence               label  \\\n",
       "17279                   Po tygodniu pytanie ponowił em .        No sentiment   \n",
       "4164   Niestety nie można też otwierać okien w pokoja...  Negative sentiment   \n",
       "11742  Inny endokrynolog od razu stwierdził że przy t...  Negative sentiment   \n",
       "13645  Leżaki od rana pozajmowane , nie ma gdzie się ...  Negative sentiment   \n",
       "6680   \" Ich badania pomogły w zrozumieniu wielu proc...        No sentiment   \n",
       "\n",
       "                                      processed_sentence  \n",
       "17279                     po tygodniu pytanie ponowil em  \n",
       "4164    niestety nie mozna tez otwierac okien w pokojach  \n",
       "11742  inny endokrynolog od razu stwierdzil ze przy t...  \n",
       "13645  lezaki od rana pozajmowane nie ma gdzie sie po...  \n",
       "6680   ich badania pomogly w zrozumieniu wielu proces...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "import enum\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "class Choice(enum.Enum):\n",
    "    Negative = \"Negative sentiment\"\n",
    "    Positive = \"Positive sentiment\"\n",
    "    NoSentiment = \"No sentiment\"\n",
    "    Unsure = \"Unsure\"\n",
    "class Sentiment(TypedDict):\n",
    "    sentence_id: int\n",
    "    sentiment: Choice\n",
    "    \n",
    "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "generation_config={\"response_mime_type\": \"application/json\",\n",
    "                   \"response_schema\": list[Sentiment]}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"output_chunks\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "chunks = [df_test.iloc[i:i + 400] for i in range(0, len(df_test), 400)]\n",
    "\n",
    "# for i, chunk in enumerate(chunks):\n",
    "#     query = '\\n'.join(f\"{index}: {row['processed_sentence']}\" for index, row in chunk.iterrows())\n",
    "#     response = model.generate_content(\n",
    "#         [\"Classify the sentiment for each sentence:\", query],\n",
    "#         generation_config=generation_config\n",
    "#     )\n",
    "    \n",
    "#     output_file = os.path.join(output_dir, f\"chunk_{i + 1}.txt\")\n",
    "#     with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "#         f.write(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "combined_data = []\n",
    "\n",
    "for filename in os.listdir(output_dir):\n",
    "    if filename.endswith('.txt'):\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        with open(filepath, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "            combined_data.extend(data)\n",
    "\n",
    "output_filepath = os.path.join(output_dir, 'combined_data.json')\n",
    "with open(output_filepath, 'w', encoding='utf-8') as output_file:\n",
    "    json.dump(combined_data, output_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Negative sentiment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Negative sentiment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>No sentiment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Negative sentiment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Positive sentiment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id           sentiment\n",
       "0            0  Negative sentiment\n",
       "1            1  Negative sentiment\n",
       "2            2        No sentiment\n",
       "3            3  Negative sentiment\n",
       "4            4  Positive sentiment"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(combined_data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75\n",
      "Confusion Matrix:\n",
      "[[1937   56  125    4]\n",
      " [  24 1430   67    1]\n",
      " [ 210  269  937    1]\n",
      " [ 280  231  161    9]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "df_test['sentence_id'] = df_test.index\n",
    "df_merged = pd.merge(df_test, df, on='sentence_id')\n",
    "df_merged['match'] = df_merged['label'] == df_merged['sentiment']\n",
    "accuracy = accuracy_score(df_merged['label'], df_merged['sentiment'])\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "cm = confusion_matrix(df_merged['label'], df_merged['sentiment'], labels=df_test['label'].unique())\n",
    "print('Confusion Matrix:')\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
