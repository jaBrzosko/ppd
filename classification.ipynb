{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_polish_lowercase(text):\n",
    "    polish_to_latin = {\n",
    "        'ą': 'a', 'ć': 'c', 'ę': 'e', 'ł': 'l', 'ń': 'n', \n",
    "        'ó': 'o', 'ś': 's', 'ź': 'z', 'ż': 'z'\n",
    "    }\n",
    "    return ''.join(polish_to_latin.get(char, char) for char in text)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Remove polish letters\n",
    "    text = replace_polish_lowercase(text)\n",
    "    # Tokenize (split by whitespace)\n",
    "    tokens = text.split()\n",
    "    return ' '.join(tokens)  # Join tokens back into a string for TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME_DEV = './data/dataset_conll/all.sentence.dev.txt'\n",
    "FILENAME_TRAIN = './data/dataset_conll/all.sentence.train.txt'\n",
    "FILENAME_TEST = './data/dataset_conll/all.sentence.test.txt'\n",
    "\n",
    "LABELS = {\n",
    "    \"__label__z_minus_m\": \"Negative sentiment\", \n",
    "    \"__label__z_plus_m\": \"Positive sentiment\",\n",
    "    \"__label__z_zero\": \"No sentiment\",\n",
    "    \"__label__z_amb\": \"Unsure\",\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df(filename):\n",
    "    with open(filename, 'r', encoding=\"utf8\") as f:\n",
    "        lines = f.readlines()\n",
    "        data = [line.strip() for line in lines]\n",
    "        # get last word from each item as a label and match with data\n",
    "        labeled_data = []\n",
    "        for item in data:\n",
    "            label = item.split()[-1]\n",
    "            sentence_data = ' '.join(item.split()[:-1])\n",
    "            labeled_data.append((sentence_data, LABELS[label]))\n",
    "\n",
    "        # create a dataframe\n",
    "        df = pd.DataFrame(labeled_data, columns=['sentence', 'label'])\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = load_df(FILENAME_TRAIN)\n",
    "df_test = load_df(FILENAME_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Early preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['processed_sentence'] = df_train['sentence'].apply(preprocess_text)\n",
    "df_test['processed_sentence'] = df_test['sentence'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>processed_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34228</th>\n",
       "      <td>Na plus położenie pensjonatu blisko deptaka i ...</td>\n",
       "      <td>Positive sentiment</td>\n",
       "      <td>na plus polozenie pensjonatu blisko deptaka i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>Pobyt w hotelu zaliczam do bardzo nieudanego .</td>\n",
       "      <td>Negative sentiment</td>\n",
       "      <td>pobyt w hotelu zaliczam do bardzo nieudanego</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8308</th>\n",
       "      <td>Operację przeprowadzono przy pomocy robota da ...</td>\n",
       "      <td>No sentiment</td>\n",
       "      <td>operacje przeprowadzono przy pomocy robota da ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32896</th>\n",
       "      <td>Zgadzam się w zupełności z powyższymi opiniami .</td>\n",
       "      <td>No sentiment</td>\n",
       "      <td>zgadzam sie w zupelnosci z powyzszymi opiniami</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16361</th>\n",
       "      <td>Na plus w pokoju codziennie uzupełniana woda .</td>\n",
       "      <td>Positive sentiment</td>\n",
       "      <td>na plus w pokoju codziennie uzupelniana woda</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence               label  \\\n",
       "34228  Na plus położenie pensjonatu blisko deptaka i ...  Positive sentiment   \n",
       "10002     Pobyt w hotelu zaliczam do bardzo nieudanego .  Negative sentiment   \n",
       "8308   Operację przeprowadzono przy pomocy robota da ...        No sentiment   \n",
       "32896   Zgadzam się w zupełności z powyższymi opiniami .        No sentiment   \n",
       "16361     Na plus w pokoju codziennie uzupełniana woda .  Positive sentiment   \n",
       "\n",
       "                                      processed_sentence  \n",
       "34228  na plus polozenie pensjonatu blisko deptaka i ...  \n",
       "10002       pobyt w hotelu zaliczam do bardzo nieudanego  \n",
       "8308   operacje przeprowadzono przy pomocy robota da ...  \n",
       "32896     zgadzam sie w zupelnosci z powyzszymi opiniami  \n",
       "16361       na plus w pokoju codziennie uzupelniana woda  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(df_train['processed_sentence'])  # Fit on train data\n",
    "X_test = vectorizer.transform(df_test['processed_sentence'])  # Transform test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the labels\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "y_train_original = df_train[['label']]\n",
    "y_test_original = df_test[['label']]\n",
    "\n",
    "y_train = encoder.fit_transform(y_train_original)  # Fit on train data labels\n",
    "y_test = encoder.transform(y_test_original)       # Transform test data labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree Classifier\n",
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(X_train, y_train)  # Fit only on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't predict 4 samples\n"
     ]
    }
   ],
   "source": [
    "# Get bit mask where prediction isn't valid one hot encoding\n",
    "valid_mask = y_pred.sum(axis=1) == 1\n",
    "y_pred = y_pred[valid_mask]\n",
    "y_test = y_test[valid_mask]\n",
    "print(f\"Couldn't predict {len(df_test) - len(y_pred)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_labels = encoder.inverse_transform(y_pred)\n",
    "y_test_labels = encoder.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.53\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test_labels, y_pred_labels)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uxeruses/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_classifier = GradientBoostingClassifier()\n",
    "gradient_classifier.fit(X_train, y_train_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gradient = gradient_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy: 0.57\n"
     ]
    }
   ],
   "source": [
    "accuracy_gradient = accuracy_score(y_test_original, y_pred_gradient)\n",
    "print(f\"Gradient Boosting Accuracy: {accuracy_gradient:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
